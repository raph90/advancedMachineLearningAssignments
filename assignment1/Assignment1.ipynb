{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COMP47590: Advanced Machine Learning\n",
    "# Assignment 1: Multi-label Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Name(s): Raphael Hetherington\n",
    "\n",
    "Student Number(s): 18200573"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Packages Etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import seaborn as sns\n",
    "import sklearn\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 0: Load the Yeast Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Att1</th>\n",
       "      <th>Att2</th>\n",
       "      <th>Att3</th>\n",
       "      <th>Att4</th>\n",
       "      <th>Att5</th>\n",
       "      <th>Att6</th>\n",
       "      <th>Att7</th>\n",
       "      <th>Att8</th>\n",
       "      <th>Att9</th>\n",
       "      <th>Att10</th>\n",
       "      <th>...</th>\n",
       "      <th>Class5</th>\n",
       "      <th>Class6</th>\n",
       "      <th>Class7</th>\n",
       "      <th>Class8</th>\n",
       "      <th>Class9</th>\n",
       "      <th>Class10</th>\n",
       "      <th>Class11</th>\n",
       "      <th>Class12</th>\n",
       "      <th>Class13</th>\n",
       "      <th>Class14</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>2417.000000</td>\n",
       "      <td>2417.000000</td>\n",
       "      <td>2417.000000</td>\n",
       "      <td>2417.000000</td>\n",
       "      <td>2417.000000</td>\n",
       "      <td>2417.000000</td>\n",
       "      <td>2417.000000</td>\n",
       "      <td>2417.000000</td>\n",
       "      <td>2417.000000</td>\n",
       "      <td>2417.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2417.000000</td>\n",
       "      <td>2417.000000</td>\n",
       "      <td>2417.000000</td>\n",
       "      <td>2417.000000</td>\n",
       "      <td>2417.000000</td>\n",
       "      <td>2417.000000</td>\n",
       "      <td>2417.000000</td>\n",
       "      <td>2417.000000</td>\n",
       "      <td>2417.000000</td>\n",
       "      <td>2417.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>0.001173</td>\n",
       "      <td>-0.000436</td>\n",
       "      <td>-0.000257</td>\n",
       "      <td>0.000265</td>\n",
       "      <td>0.001228</td>\n",
       "      <td>0.000475</td>\n",
       "      <td>0.001107</td>\n",
       "      <td>0.000420</td>\n",
       "      <td>0.001076</td>\n",
       "      <td>-0.000009</td>\n",
       "      <td>...</td>\n",
       "      <td>0.298717</td>\n",
       "      <td>0.247000</td>\n",
       "      <td>0.177079</td>\n",
       "      <td>0.198593</td>\n",
       "      <td>0.073645</td>\n",
       "      <td>0.104675</td>\n",
       "      <td>0.119570</td>\n",
       "      <td>0.751345</td>\n",
       "      <td>0.744311</td>\n",
       "      <td>0.014067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>0.097411</td>\n",
       "      <td>0.097885</td>\n",
       "      <td>0.097746</td>\n",
       "      <td>0.096969</td>\n",
       "      <td>0.096909</td>\n",
       "      <td>0.097306</td>\n",
       "      <td>0.097170</td>\n",
       "      <td>0.096803</td>\n",
       "      <td>0.096326</td>\n",
       "      <td>0.096805</td>\n",
       "      <td>...</td>\n",
       "      <td>0.457790</td>\n",
       "      <td>0.431356</td>\n",
       "      <td>0.381815</td>\n",
       "      <td>0.399024</td>\n",
       "      <td>0.261246</td>\n",
       "      <td>0.306198</td>\n",
       "      <td>0.324525</td>\n",
       "      <td>0.432323</td>\n",
       "      <td>0.436338</td>\n",
       "      <td>0.117792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>-0.371146</td>\n",
       "      <td>-0.472632</td>\n",
       "      <td>-0.339195</td>\n",
       "      <td>-0.467945</td>\n",
       "      <td>-0.367044</td>\n",
       "      <td>-0.509447</td>\n",
       "      <td>-0.319928</td>\n",
       "      <td>-0.594498</td>\n",
       "      <td>-0.369712</td>\n",
       "      <td>-0.767128</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>-0.053655</td>\n",
       "      <td>-0.058734</td>\n",
       "      <td>-0.057526</td>\n",
       "      <td>-0.057149</td>\n",
       "      <td>-0.058461</td>\n",
       "      <td>-0.060212</td>\n",
       "      <td>-0.058445</td>\n",
       "      <td>-0.062849</td>\n",
       "      <td>-0.063472</td>\n",
       "      <td>-0.065010</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>0.003649</td>\n",
       "      <td>-0.003513</td>\n",
       "      <td>0.002892</td>\n",
       "      <td>-0.000153</td>\n",
       "      <td>0.005565</td>\n",
       "      <td>0.000321</td>\n",
       "      <td>0.006179</td>\n",
       "      <td>0.001436</td>\n",
       "      <td>0.003515</td>\n",
       "      <td>0.002432</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>0.057299</td>\n",
       "      <td>0.048047</td>\n",
       "      <td>0.061007</td>\n",
       "      <td>0.054522</td>\n",
       "      <td>0.066286</td>\n",
       "      <td>0.059908</td>\n",
       "      <td>0.068892</td>\n",
       "      <td>0.061418</td>\n",
       "      <td>0.064958</td>\n",
       "      <td>0.063096</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>0.520272</td>\n",
       "      <td>0.614114</td>\n",
       "      <td>0.353241</td>\n",
       "      <td>0.568960</td>\n",
       "      <td>0.307649</td>\n",
       "      <td>0.336971</td>\n",
       "      <td>0.351401</td>\n",
       "      <td>0.454591</td>\n",
       "      <td>0.419852</td>\n",
       "      <td>0.420876</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 117 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Att1         Att2         Att3         Att4         Att5  \\\n",
       "count  2417.000000  2417.000000  2417.000000  2417.000000  2417.000000   \n",
       "mean      0.001173    -0.000436    -0.000257     0.000265     0.001228   \n",
       "std       0.097411     0.097885     0.097746     0.096969     0.096909   \n",
       "min      -0.371146    -0.472632    -0.339195    -0.467945    -0.367044   \n",
       "25%      -0.053655    -0.058734    -0.057526    -0.057149    -0.058461   \n",
       "50%       0.003649    -0.003513     0.002892    -0.000153     0.005565   \n",
       "75%       0.057299     0.048047     0.061007     0.054522     0.066286   \n",
       "max       0.520272     0.614114     0.353241     0.568960     0.307649   \n",
       "\n",
       "              Att6         Att7         Att8         Att9        Att10  ...  \\\n",
       "count  2417.000000  2417.000000  2417.000000  2417.000000  2417.000000  ...   \n",
       "mean      0.000475     0.001107     0.000420     0.001076    -0.000009  ...   \n",
       "std       0.097306     0.097170     0.096803     0.096326     0.096805  ...   \n",
       "min      -0.509447    -0.319928    -0.594498    -0.369712    -0.767128  ...   \n",
       "25%      -0.060212    -0.058445    -0.062849    -0.063472    -0.065010  ...   \n",
       "50%       0.000321     0.006179     0.001436     0.003515     0.002432  ...   \n",
       "75%       0.059908     0.068892     0.061418     0.064958     0.063096  ...   \n",
       "max       0.336971     0.351401     0.454591     0.419852     0.420876  ...   \n",
       "\n",
       "            Class5       Class6       Class7       Class8       Class9  \\\n",
       "count  2417.000000  2417.000000  2417.000000  2417.000000  2417.000000   \n",
       "mean      0.298717     0.247000     0.177079     0.198593     0.073645   \n",
       "std       0.457790     0.431356     0.381815     0.399024     0.261246   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "50%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "75%       1.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "max       1.000000     1.000000     1.000000     1.000000     1.000000   \n",
       "\n",
       "           Class10      Class11      Class12      Class13      Class14  \n",
       "count  2417.000000  2417.000000  2417.000000  2417.000000  2417.000000  \n",
       "mean      0.104675     0.119570     0.751345     0.744311     0.014067  \n",
       "std       0.306198     0.324525     0.432323     0.436338     0.117792  \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000  \n",
       "25%       0.000000     0.000000     1.000000     0.000000     0.000000  \n",
       "50%       0.000000     0.000000     1.000000     1.000000     0.000000  \n",
       "75%       0.000000     0.000000     1.000000     1.000000     0.000000  \n",
       "max       1.000000     1.000000     1.000000     1.000000     1.000000  \n",
       "\n",
       "[8 rows x 117 columns]"
      ]
     },
     "execution_count": 303,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Write your code here\n",
    "data = pd.read_csv(\"yeast.csv\")\n",
    "data.describe()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1: Implement the Binary Relevance Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "To use the Binary Relevance class, you need to pass in the specific list of labels that you want to choose from.\n",
    "The algorithm will then go through each, create a model based on each, and then aggregate the findings. \n",
    "\n",
    "'''\n",
    "class BinaryRelevance():\n",
    "    def __init__(self, classifier, class_labels):\n",
    "        # pass in a classifier object\n",
    "        # the number of class labels is necessary so that we know where to start slicing from \n",
    "        self.classifier = classifier\n",
    "        self.class_labels = class_labels # should be a list\n",
    "        self.models = {}\n",
    "        self.labels_series = pd.Series(self.class_labels)\n",
    "         \n",
    "    \n",
    "    def trajin(self, data_to_train):\n",
    "        # first step is simply to pass in a subset of the data. \n",
    "        # We just want one batch of the data and another batch\n",
    "        '''\n",
    "        Step 1: \n",
    "            For each class label we have to strip away the others, and make a model with the class label.\n",
    "            We're ultimately going to be using an aggregation of these models, so we store the models that \n",
    "            we create in the models dictionary.\n",
    "        ''' \n",
    "        # the features are all the columns that are not the class labels\n",
    "        features = data_to_train[data_to_train.columns[~data_to_train.columns.isin(self.labels_series)]]\n",
    "        \n",
    "        # for each class label we create a new model\n",
    "        for class_label in self.class_labels:\n",
    "            # the model is stored in self.models\n",
    "            self.models[class_label] = self.classifier()\n",
    "            # we select the class label column as our y\n",
    "            y = data_to_train[[class_label]]\n",
    "            # we train the model\n",
    "            self.models[class_label].fit(features, y.values.ravel())\n",
    "\n",
    "\n",
    "    # Inputs: this method receives a dataframe WITHOUT class labels and returns a dataframe with the class labels predicted\n",
    "    def predict(self, features):\n",
    "            return_frame = features\n",
    "            for class_label in self.class_labels:\n",
    "                model = self.models[class_label]# select the appropriate model from the dictionary\n",
    "                prediction = model.predict(features) \n",
    "                prediction_frame = pd.DataFrame(data=prediction, columns=[class_label]) # create a new df with the prediction\n",
    "                return_frame = return_frame.reset_index(drop=True) # reset index\n",
    "                prediction_frame = prediction_frame.reset_index(drop=True) # reset index\n",
    "                return_frame = pd.concat([return_frame, prediction_frame], axis=1) # concatenate the class label with the features\n",
    "            return return_frame\n",
    "            \n",
    "                \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2: Implement the Binary Relevance Algorithm with Under-Sampling\n",
    "Our objective is to balance the class distribution for each label. We can do this by:  \n",
    "1) Evaluating the class distribution for each class  \n",
    "2) If the classes are imbalanced, we can remove a subset of the data to balance them. \n",
    "\n",
    "To enact undersampling, I'm going to create a subclass of the BinaryRelevance class, called BinaryRelevanceWithUnderSampling. This class will have a method - balance_classes_and_train. This method will:\n",
    "- assess each label and the distribution of classes\n",
    "- produce a balanced dataframe **if required**\n",
    "- train a model\n",
    "- revert back to the original \"full\" dataframe and repeat so as to keep as much data available as possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BinaryRelevanceWithUnderSampling(BinaryRelevance):\n",
    "    def __init__(self, classifier, labels):\n",
    "        super().__init__(classifier, labels)\n",
    "    \n",
    "    \n",
    "    def balance_classes_and_train(self, data_to_train):\n",
    "        for class_label in self.class_labels:\n",
    "            # first check the distribution of classes \n",
    "            with_label = data_to_train.loc[data_to_train[class_label] == 1]\n",
    "            without_label = data_to_train.loc[data_to_train[class_label] == 0]\n",
    "            # find the majority and minority of with_label/without_label\n",
    "            shorter = with_label if len(with_label) < len(without_label) else without_label\n",
    "            longer = with_label if len(with_label) > len(without_label) else without_label\n",
    "#             take a subset of the majority class that is the same length as the minority class\n",
    "            sub_sample = longer.sample(n=len(shorter), random_state=42)\n",
    "#           create a new data frame that combines the two\n",
    "            sub_sampled_df = pd.concat([shorter, sub_sample]).reset_index()\n",
    "            # create classifier\n",
    "            self.models[class_label] = self.classifier()\n",
    "            features = sub_sampled_df[sub_sampled_df.columns[~sub_sampled_df.columns.isin(self.labels_series)]]\n",
    "            features = features.drop(labels='index', axis=1)\n",
    "            y = sub_sampled_df[[class_label]]\n",
    "            self.models[class_label].fit(features, y.values.ravel())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3: Compare the Performance of Different Binary Relevance Approaches\n",
    "\n",
    "### Evaluation Strategies\n",
    "\n",
    "We are going to assess the performance of our algorithms in the following ways:\n",
    "\n",
    "1. Experimenting with different base classifiers. In our case we will use three common classification algorithms: \n",
    "    - Naive Bayes\n",
    "    - Logistic Regression \n",
    "    and  \n",
    "    - K-Nearest Neighbours  \n",
    "\n",
    "and   \n",
    "\n",
    "2. Using hamming loss, macro-averaged accuracy score and macro-averaged f-score to measure the performance of each classifier.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/raph/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/raph/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/raph/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/raph/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/raph/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/raph/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/raph/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/raph/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/raph/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/raph/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/raph/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/raph/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/raph/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/raph/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/raph/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/raph/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/raph/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/raph/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/raph/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/raph/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/raph/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/raph/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/raph/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/raph/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/raph/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/raph/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/raph/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/raph/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import hamming_loss\n",
    "\n",
    "    \n",
    "\n",
    "# Create training and testing sets\n",
    "train, test = np.split(data, [int(.7*len(data))]) # I split the dataframe into 70% train and 30% test\n",
    "train # 1691 rows\n",
    "test # 726 rows\n",
    "\n",
    "\n",
    "# Binary Relevance: \n",
    "\n",
    "# get all class labels\n",
    "test_class_label_results = test.loc[:, 'Class1':]\n",
    "prediction_class_label_results_with_undersampling = binary_relevance_with_undersampling.loc[:, 'Class1':]\n",
    "prediction_class_label_results_without_undersampling = binary_relevance_without_undersampling.loc[:, 'Class1':]\n",
    "\n",
    "# reset indices\n",
    "prediction_class_label_results_with_undersampling.reset_index()\n",
    "prediction_class_label_results_without_undersampling.reset_index()\n",
    "test_class_label_results = test_class_label_results.reset_index()\n",
    "test_class_label_results = test_class_label_results.drop(\"index\", axis=1)\n",
    "\n",
    "# classifiers:\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB # our test classifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "class_labels = ['Class1', 'Class2', 'Class3', 'Class4', 'Class5', 'Class6', 'Class7', 'Class8', 'Class9', 'Class10', 'Class11', 'Class12', 'Class13', 'Class14']\n",
    "\n",
    "\n",
    "# # Binary Relevance Classifiers\n",
    "br_reg_classifier = BinaryRelevance(LogisticRegression, class_labels) \n",
    "br_reg_classifier.train(train)\n",
    "br_nb_classifier = BinaryRelevance(GaussianNB, class_labels) \n",
    "br_nb_classifier.train(train)\n",
    "br_knn_classifier = BinaryRelevance(KNeighborsClassifier, class_labels)\n",
    "br_knn_classifier.train(train)\n",
    "\n",
    "\n",
    "# undersampling classifiers\n",
    "us_reg_classifier = BinaryRelevanceWithUnderSampling(LogisticRegression, class_labels) \n",
    "us_reg_classifier.balance_classes_and_train(train)\n",
    "us_nb_classifier = BinaryRelevanceWithUnderSampling(GaussianNB, class_labels) \n",
    "us_nb_classifier.balance_classes_and_train(train)\n",
    "us_knn_classifier = BinaryRelevanceWithUnderSampling(KNeighborsClassifier, class_labels)\n",
    "us_knn_classifier.balance_classes_and_train(train)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing set without class labels\n",
    "test_features = test[test.columns[~test.columns.isin(class_labels)]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "br_reg_predictions = br_reg_classifier.predict(test_features)\n",
    "br_nb_predictions = br_nb_classifier.predict(test_features)\n",
    "br_knn_predictions = br_knn_classifier.predict(test_features)\n",
    "us_reg_predictions = us_reg_classifier.predict(test_features)\n",
    "us_nb_predictions = us_nb_classifier.predict(test_features)\n",
    "us_knn_predictions = us_knn_classifier.predict(test_features)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Macro-averaged Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy for  binary_relevance_logistic_regression  is  0.7971271153089335\n",
      "accuracy for  binary_relevance_naive_bayes  is  0.698150334513971\n",
      "accuracy for  binary_relevance_knn  is  0.7888626524990162\n",
      "accuracy for  undersampled_logistic_regression  is  0.6250491932310114\n",
      "accuracy for  undersampled_naive_bayes  is  0.6201298701298701\n",
      "accuracy for  undersampled_knn  is  0.6294765840220385\n"
     ]
    }
   ],
   "source": [
    "# accuracy without undersampling\n",
    "\n",
    "classifiersToEvaluate = {\n",
    "    \"binary_relevance_logistic_regression\": br_reg_predictions,\n",
    "    \"binary_relevance_naive_bayes\": br_nb_predictions,\n",
    "    \"binary_relevance_knn\": br_knn_predictions,\n",
    "    \"undersampled_logistic_regression\": us_reg_predictions,\n",
    "    \"undersampled_naive_bayes\": us_nb_predictions,\n",
    "    \"undersampled_knn\": us_knn_predictions\n",
    "}\n",
    "\n",
    "for key, value in classifiersToEvaluate.items():\n",
    "    cumulative_accuracy = 0\n",
    "    for class_label in class_labels:\n",
    "        val_to_add = accuracy_score(test_class_label_results[class_label], value[class_label])\n",
    "        cumulative_accuracy += val_to_add\n",
    "    averaged_accuracy = cumulative_accuracy / len(class_labels)\n",
    "    print(\"accuracy for \", key, \" is \", averaged_accuracy)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Results\n",
    "\n",
    "Accuracy without undersampling: 80%, 70% and 79%   \n",
    "Accuracy with undersampling: 63%, 62%, 63%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Macro-averaged F1 Measure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 measure for  binary_relevance_logistic_regression  is  0.3470882117611737\n",
      "f1 measure for  binary_relevance_naive_bayes  is  0.44663364040197173\n",
      "f1 measure for  binary_relevance_knn  is  0.40798443921699407\n",
      "f1 measure for  undersampled_logistic_regression  is  0.45071613455204557\n",
      "f1 measure for  undersampled_naive_bayes  is  0.4415479688600657\n",
      "f1 measure for  undersampled_knn  is  0.4545034543133587\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/raph/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "for key, value in classifiersToEvaluate.items():\n",
    "    cumulative_accuracy = 0\n",
    "    for class_label in class_labels:\n",
    "        val_to_add = f1_score(test_class_label_results[class_label], value[class_label])\n",
    "        cumulative_accuracy += val_to_add\n",
    "    averaged_accuracy = cumulative_accuracy / len(class_labels)\n",
    "    print(\"f1 measure for \", key, \" is \", averaged_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results\n",
    "\n",
    "F1 without undersampling: 35%, 45%, 41%   \n",
    "F1 with undersampling: 45%, 44%, 45%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hamming Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hamming loss for  binary_relevance_logistic_regression  is  0.2028728846910665\n",
      "hamming loss for  binary_relevance_naive_bayes  is  0.3018496654860291\n",
      "hamming loss for  binary_relevance_knn  is  0.21113734750098387\n",
      "hamming loss for  undersampled_logistic_regression  is  0.37495080676898856\n",
      "hamming loss for  undersampled_naive_bayes  is  0.37987012987012986\n",
      "hamming loss for  undersampled_knn  is  0.37052341597796146\n"
     ]
    }
   ],
   "source": [
    "for key, value in classifiersToEvaluate.items():\n",
    "    comparison_cols = value.loc[:, \"Class1\":]\n",
    "    hamming_score = hamming_loss(test_class_label_results, comparison_cols)\n",
    "    print(\"hamming loss for \", key, \" is \", hamming_score)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results:\n",
    "- without undersampling: 20%, 30%, 21% - avg = 24%\n",
    "- with undersampling: 37%, 38%, 37% - avg = 37%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4: Implement the Classifier Chains Algorithm\n",
    "\n",
    "Classifier chains work by using the cumulative predictions of previous models to create iteratively more accurate predictions. They differ from binary relevance in that the class labels are no longer seen as independent. \n",
    "\n",
    "In order to implement a classifier chain algorithm, we need to:  \n",
    "Train:\n",
    "- train a model for the first class with the feature set. \n",
    "- append that class label to the feature set\n",
    "- train the next model with the new, extended feature set\n",
    "- Repeat.\n",
    "\n",
    "Predict: \n",
    "- Make a prediction for label 1 with the test set instances.\n",
    "- Append that prediction to the test set and then move onto the next feature label. \n",
    "- Repeat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassifierChains():\n",
    "    def __init__(self, classifier, class_labels):\n",
    "        # pass in a classifier object\n",
    "        # the number of class labels is necessary so that we know where to start slicing from \n",
    "        self.classifier = classifier\n",
    "        self.class_labels = class_labels # should be a list\n",
    "        self.models = {}\n",
    "        self.labels_series = pd.Series(self.class_labels)\n",
    "         \n",
    "    # in the training phase, we train the model for Class1, then \n",
    "    # concat the features with the true values for class1, then\n",
    "    # use the extended feature set to train the model for Class2 etc. \n",
    "    def train(self, data_to_train):\n",
    "        features = data_to_train[data_to_train.columns[~data_to_train.columns.isin(self.labels_series)]]\n",
    "        # for each class label we create a new model\n",
    "        for class_label in self.class_labels:\n",
    "            # the model is stored in self.models\n",
    "            self.models[class_label] = self.classifier()\n",
    "            # we select the class label column as our y\n",
    "            y = data_to_train[[class_label]]\n",
    "            # we train the model\n",
    "            self.models[class_label].fit(features, y.values.ravel())\n",
    "            # chain on the class label\n",
    "            features = pd.concat([features, y], axis=1)\n",
    "\n",
    "    # for predicting, we have to chain on our predictions before we pass to the next model.\n",
    "    def predict(self, features):\n",
    "            return_frame = features\n",
    "            for class_label in self.class_labels:\n",
    "                model = self.models[class_label]# select the appropriate model from the dictionary\n",
    "                prediction = model.predict(features)\n",
    "                # concat our prediction\n",
    "                prediction_frame = pd.DataFrame(data=prediction, columns=[class_label]) # create a new df with the prediction\n",
    "                return_frame = return_frame.reset_index(drop=True) # reset index\n",
    "                prediction_frame = prediction_frame.reset_index(drop=True) # reset index\n",
    "                \n",
    "                # Chaining! This is where we concatenate the prediction onto the feature space\n",
    "                features = pd.concat([return_frame, prediction_frame], axis=1)\n",
    "                return_frame = pd.concat([return_frame, prediction_frame], axis=1) # concatenate the class label with the features\n",
    "            return return_frame\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 5: Evaluate the Performance of the Classifier Chains Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/raph/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/raph/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/raph/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/raph/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/raph/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/raph/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/raph/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/raph/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/raph/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/raph/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/raph/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/raph/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/raph/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/raph/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "cc_reg_classifier = ClassifierChains(LogisticRegression, class_labels) \n",
    "cc_reg_classifier.train(train)\n",
    "cc_nb_classifier = ClassifierChains(GaussianNB, class_labels) \n",
    "cc_nb_classifier.train(train)\n",
    "cc_knn_classifier = ClassifierChains(KNeighborsClassifier, class_labels)\n",
    "cc_knn_classifier.train(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc_reg_predictions = cc_reg_classifier.predict(test_features)\n",
    "cc_nb_predictions = cc_nb_classifier.predict(test_features)\n",
    "cc_knn_predictions = cc_knn_classifier.predict(test_features)\n",
    "\n",
    "cc_evaluate = {\n",
    "    \"cc_logistic_regression\": cc_reg_predictions,\n",
    "    \"cc_naive_bayes\": cc_nb_predictions,\n",
    "    \"cc_knn\": cc_knn_predictions,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy for  cc_logistic_regression  is  0.7856158992522628\n",
      "accuracy for  cc_naive_bayes  is  0.6860487996851632\n",
      "accuracy for  cc_knn  is  0.778728846910665\n"
     ]
    }
   ],
   "source": [
    "for key, value in cc_evaluate.items():\n",
    "    cumulative_accuracy = 0\n",
    "    for class_label in class_labels:\n",
    "        val_to_add = accuracy_score(test_class_label_results[class_label], value[class_label])\n",
    "        cumulative_accuracy += val_to_add\n",
    "    averaged_accuracy = cumulative_accuracy / len(class_labels)\n",
    "    print(\"accuracy for \", key, \" is \", averaged_accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### F1 Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 score for  cc_logistic_regression  is  0.38729133518247766\n",
      "f1 score for  cc_naive_bayes  is  0.4455026823600304\n",
      "f1 score for  cc_knn  is  0.41666830999808824\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/raph/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "for key, value in cc_evaluate.items():\n",
    "    cumulative_accuracy = 0\n",
    "    for class_label in class_labels:\n",
    "        val_to_add = f1_score(test_class_label_results[class_label], value[class_label])\n",
    "        cumulative_accuracy += val_to_add\n",
    "    averaged_accuracy = cumulative_accuracy / len(class_labels)\n",
    "    print(\"f1 score for \", key, \" is \", averaged_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hamming Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hamming loss for  cc_logistic_regression  is  0.21438410074773712\n",
      "hamming loss for  cc_naive_bayes  is  0.3139512003148367\n",
      "hamming loss for  cc_knn  is  0.2212711530893349\n"
     ]
    }
   ],
   "source": [
    "for key, value in cc_evaluate.items():\n",
    "    comparison_cols = value.loc[:, \"Class1\":]\n",
    "    hamming_score = hamming_loss(test_class_label_results, comparison_cols)\n",
    "    print(\"hamming loss for \", key, \" is \", hamming_score)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The scores for BR:  20%, 30%, 21% - avg = 24%\n",
    "The scores for CC: 21%, 31%, 22% - avg = 25%\n",
    "\n",
    "Again we can see a slight improvement in the case of the Hamming Loss, but not by a great amount."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 6: Reflect on the Performance of the Different Models Evaluated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interestingly the binary relevance classifier without undersampling was more accurate than the undersampled one. The undersampling strategy is clearly visible in how closely the different base classifiers perform, given that the data is balanced (but also drastically reduced in volume in some cases).  \n",
    "In the case of the F1 score, we can see that undersampling benefitted the overall models, with an average F1 of 40% for the models that weren't undersampled, against 45% in the case of the undersampled ones. \n",
    "We can also see that undersampling drastically improved the performance of our classification in the case of hamming loss, with an average HL of 24% without undersampling, and 37% with it.\n",
    "\n",
    "In the case of classifier chains, I used a non-under sampled approach, so we ought to compare these scores against our non-undersampled binary relevance algorithm.\n",
    "\n",
    "The BR algorithm scored: 80%, 70% and 79%\n",
    "The CC algorithm score: 79%, 69% and 78%\n",
    "\n",
    "We can see that the CC algorithm is marginally worse here. It may well be the case that incorrect predictions in prior models might negatively affect predictions made by later models i.e the chaining is actually having a detrimental effect. \n",
    "\n",
    "For the non-undersampled BR the averaged F1 scores were: 35%, 45%, 41%, while in CC the averaged F1 scores were: 39%, 45%, 42%, which, encouragingly, shows an improvement. However, the Hamming Loss, while improved with CC, was still very low, with an average of 25%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
